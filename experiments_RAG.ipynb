{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with RAG\n",
    "\n",
    "In this notebook, I test different RAG systems within the **LlamaIndex** framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "from llama_index import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index import ServiceContext, StorageContext\n",
    "from llama_index import load_index_from_storage\n",
    "from llama_index import OpenAIEmbedding\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.indices.query.query_transform import HyDEQueryTransform\n",
    "from llama_index.query_engine.transform_query_engine import TransformQueryEngine\n",
    "\n",
    "import openai\n",
    "import environ\n",
    "\n",
    "env = environ.Env()\n",
    "environ.Env.read_env()\n",
    "API_KEY = env('OPENAI_API_KEY')\n",
    "openai.api_key = API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "docs_path = \"documents_pdf\"\n",
    "embedding_path = \"vector_db\"\n",
    "\n",
    "llm= OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    \"chunk_size\": [256], # [256, 512, 1024]\n",
    "    \"top_k_results\": [5] # [1, 3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "def load_docs(doc_path):\n",
    "    docs = SimpleDirectoryReader(input_dir=doc_path).load_data()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_db(docs, llm, embed_model):\n",
    "    \"\"\"\n",
    "    Build an index (vector database using the VectorStoreIndex class of LlamaIndex).\n",
    "\n",
    "    Args:\n",
    "        docs (Document): An object of the Document class from LlamaIndex.\n",
    "        llm: OpenAI Chat large language models API.\n",
    "            Example: llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "        embed_model: OpenAI embedding models.\n",
    "            Example: llm_emb = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "    Returns:\n",
    "        index (VectorStoreIndex): An object of the VectorStoreIndex class from \n",
    "            LlamaIndex to use to build a query engine.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # Define The ServiceContext: a bundle of commonly used resources used during\n",
    "    # the indexing and querying stage in a LlamaIndex pipeline/application.\n",
    "    service_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model\n",
    "    )\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # Storage context: The storage context container is a utility container for storing \n",
    "    # nodes, indices, and vectors. It contains the following:\n",
    "    # - docstore: BaseDocumentStore\n",
    "    # - index_store: BaseIndexStore\n",
    "    # - vector_store: VectorStore\n",
    "    # - graph_store: GraphStore\n",
    "    storage_context = StorageContext.from_defaults()\n",
    "\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # VectorStoreIndex: a data structure that allows for the retrieval of relevant context\n",
    "    # for a user query. This is particularly useful for retrieval-augmented generation (RAG) use-cases.\n",
    "    # VectorStoreIndex stores data in Node objects, which represent chunks of the original documents,\n",
    "    # and exposes a Retriever interface that supports additional configuration and automation.\n",
    "    print(\"Creating Vector Database ...\")\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents=docs,\n",
    "        service_context=service_context,\n",
    "        storage_context=storage_context,\n",
    "        show_progress=True\n",
    "    )\n",
    "    print(\"Done\")\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_docs(docs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Vector Database ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 774/774 [00:00<00:00, 2829.57it/s]\n",
      "Generating embeddings: 100%|██████████| 778/778 [00:15<00:00, 50.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "index = create_vector_db(docs, llm, embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User query\n",
    "# user_query = \"What percentage of my salary I get as unemployment benefit?\"\n",
    "user_query = \"\"\"\n",
    "I worked for six months in Germany.\n",
    "How long will I get the unemployment benefit,\n",
    "and what percentage of my salary I get?\n",
    "\"\"\" \n",
    "\n",
    "\n",
    "# Build an object of the QueryEngine class\n",
    "query_engine = index.as_query_engine(similarity_top_k=param_dict[\"top_k_results\"][0])\n",
    "\n",
    "# Query engine with base RAG\n",
    "response = query_engine.query(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_response(response):\n",
    "    print(\"Response:\")\n",
    "    # print(response.response)\n",
    "    display(Markdown(response.response))\n",
    "    for i, meta_data in enumerate(response.metadata):   \n",
    "        print(f\"Source {i}:\")\n",
    "        print(f\"\\tFile name: {response.metadata[meta_data]['file_name']}\")\n",
    "        print(f\"\\tPage: {response.metadata[meta_data]['page_label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The duration of unemployment benefits in Germany depends on various factors, such as your previous employment history and the length of time you have contributed to the social security system. Generally, you can receive unemployment benefits for up to 12 months if you have paid into the system for at least 12 months. However, if you have worked for six months in Germany, the specific duration and percentage of your salary you will receive as unemployment benefits would need to be determined based on your individual circumstances and the applicable regulations. It is recommended to contact the relevant authorities, such as the Federal Employment Agency (Bundesagentur für Arbeit), to get accurate and up-to-date information regarding your specific situation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source 0:\n",
      "\tFile name: dok_ba013155.pdf\n",
      "\tPage: 26\n",
      "Source 1:\n",
      "\tFile name: dok_ba013155.pdf\n",
      "\tPage: 22\n",
      "Source 2:\n",
      "\tFile name: merkblatt-fuer-arbeitslose_ba036520.pdf\n",
      "\tPage: 26\n",
      "Source 3:\n",
      "\tFile name: dok_ba013155.pdf\n",
      "\tPage: 24\n",
      "Source 4:\n",
      "\tFile name: dok_ba013155.pdf\n",
      "\tPage: 20\n"
     ]
    }
   ],
   "source": [
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG - chunk size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_db_path = f\"{embedding_path}/vector_db_1\"\n",
    "# print(f\"Path: {vector_db_path}\")\n",
    "# print(f\"Path exist: {os.path.exists(vector_db_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index_from_file(folder_with_index):\n",
    "    \"\"\"\n",
    "    Rebuild storage context from a vector database and return a query engine.\n",
    "\n",
    "    Args:\n",
    "        folder_with_index (str): Folder where the vector database is.\n",
    "\n",
    "    Returns:\n",
    "        index (VectorStoreIndex): An object of the VectorStoreIndex class from \n",
    "            LlamaIndex to use to build a query engine.\n",
    "    \"\"\"\n",
    "    # rebuild storage context\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=folder_with_index)\n",
    "    # load index\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_db_chunksize(docs, vector_db_folder, llm, embed_model, chunk_size, chunk_overlap=0):\n",
    "    \"\"\"\n",
    "    Build an index (vector database using the VectorStoreIndex class of LlamaIndex).\n",
    "\n",
    "    Args:\n",
    "        docs (Document): An object of the Document class from LlamaIndex.\n",
    "        vector_db_folder (str): Folder where to save or load the index.\n",
    "        llm: OpenAI Chat large language models API.\n",
    "            Example: llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "        embed_model: OpenAI embedding models.\n",
    "            Example: llm_emb = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "        chunk_size (Int): chunck size.\n",
    "        chunk_overlap (Int): = sentence chunk overlap (default=0).\n",
    "\n",
    "    Returns:\n",
    "        index (VectorStoreIndex): An object of the VectorStoreIndex class from \n",
    "            LlamaIndex to use to build a query engine.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the path to save the vector db\n",
    "    vector_db_path = f\"{vector_db_folder}/vector_db_{chunk_size}\"\n",
    "    \n",
    "    if not os.path.exists(vector_db_path):\n",
    "        # Create the folder that contains the vector database\n",
    "        # Path(vector_db_path).mkdir(parents=True, exist_ok=True)\n",
    "        Path(vector_db_path).mkdir()\n",
    "\n",
    "        # ----------------------------------------------------------------------------------\n",
    "        # Define SimpleNodeParser: a node parser used to split a document loaded from a file\n",
    "        # into Nodes (automatically detects the NodeParser to use based on file type).\n",
    "        node_parser = SimpleNodeParser.from_defaults(\n",
    "            chunk_size=chunk_size,\n",
    "            #chunk_overlap=chunk_overlap,\n",
    "        )\n",
    "        nodes = node_parser.get_nodes_from_documents(docs)\n",
    "    \n",
    "        # ----------------------------------------------------------------------------------\n",
    "        # Define The ServiceContext: A bundle of commonly used resources used during\n",
    "        # the indexing and querying stage in a LlamaIndex pipeline/application.\n",
    "        service_context = ServiceContext.from_defaults(\n",
    "            llm=llm,\n",
    "            embed_model=embed_model\n",
    "        )\n",
    "    \n",
    "        # ----------------------------------------------------------------------------------\n",
    "        # Storage context: The storage context container is a utility container for storing \n",
    "        # nodes, indices, and vectors. It contains the following:\n",
    "        # - docstore: BaseDocumentStore\n",
    "        # - index_store: BaseIndexStore\n",
    "        # - vector_store: VectorStore\n",
    "        # - graph_store: GraphStore\n",
    "        storage_context = StorageContext.from_defaults()\n",
    "\n",
    "        # ----------------------------------------------------------------------------------\n",
    "        # VectorStoreIndex: a data structure that allows for the retrieval of relevant context\n",
    "        # for a user query. This is particularly useful for retrieval-augmented generation (RAG) use-cases.\n",
    "        # VectorStoreIndex stores data in Node objects, which represent chunks of the original documents,\n",
    "        # and exposes a Retriever interface that supports additional configuration and automation.\n",
    "        print(\"Creating Vector Database ...\")\n",
    "        index = VectorStoreIndex(\n",
    "            nodes=nodes,\n",
    "            service_context=service_context,\n",
    "            storage_context=storage_context,\n",
    "            show_progress=True\n",
    "        )\n",
    "\n",
    "        print(\"Saving Vector Database ...\")\n",
    "        index.storage_context.persist(persist_dir=vector_db_path)\n",
    "        print(\"Done\")\n",
    "        \n",
    "    else:\n",
    "        index = build_index_from_file(vector_db_path)\n",
    "\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_chunk_size = create_vector_db_chunksize(\n",
    "    docs=docs,\n",
    "    vector_db_folder=embedding_path,\n",
    "    llm=llm,\n",
    "    embed_model=embed_model,\n",
    "    chunk_size=param_dict[\"chunk_size\"][0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an object of the QueryEngine class\n",
    "query_engine_chunk_size = index_chunk_size.as_query_engine(similarity_top_k=param_dict[\"top_k_results\"][0])\n",
    "\n",
    "# Query engine with base RAG\n",
    "response_chunk_size = query_engine_chunk_size.query(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "You will be eligible for unemployment benefits in Germany for a maximum duration of six months. The percentage of your salary that you will receive as unemployment benefits is not mentioned in the provided context information."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source 0:\n",
      "\tFile name: dok_ba013155.pdf\n",
      "\tPage: 22\n",
      "Source 1:\n",
      "\tFile name: dok_ba013155.pdf\n",
      "\tPage: 22\n",
      "Source 2:\n",
      "\tFile name: merkblatt-fuer-arbeitslose_ba036520.pdf\n",
      "\tPage: 26\n",
      "Source 3:\n",
      "\tFile name: dok_ba013155.pdf\n",
      "\tPage: 24\n",
      "Source 4:\n",
      "\tFile name: dok_ba013155.pdf\n",
      "\tPage: 26\n"
     ]
    }
   ],
   "source": [
    "print_response(response_chunk_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyde = HyDEQueryTransform(include_original=True)\n",
    "hyde_query_engine = TransformQueryEngine(query_engine, hyde)\n",
    "response_HyDE = hyde_query_engine.query(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The duration of your unemployment benefit and the percentage of your salary that you will receive will depend on various factors, such as the length of your employment and your age. Based on the provided context information, it states that if you have worked for at least 12 months within the last 30 months, you may be eligible for a certain duration of unemployment benefit. However, the specific details regarding the duration and percentage cannot be determined without further information. It is recommended to consult the relevant authorities or refer to the specific regulations and guidelines in your country for accurate information regarding your eligibility and entitlements."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source 0:\n",
      "\tFile name: dok_ba013155.pdf\n",
      "\tPage: 26\n",
      "Source 1:\n",
      "\tFile name: dok_ba013155.pdf\n",
      "\tPage: 22\n",
      "Source 2:\n",
      "\tFile name: merkblatt-fuer-arbeitslose_ba036520.pdf\n",
      "\tPage: 26\n",
      "Source 3:\n",
      "\tFile name: merkblatt-fuer-arbeitslose_ba036520.pdf\n",
      "\tPage: 33\n",
      "Source 4:\n",
      "\tFile name: merkblatt-fuer-arbeitslose_ba036520.pdf\n",
      "\tPage: 32\n"
     ]
    }
   ],
   "source": [
    "print_response(response_HyDE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG - chuck size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyde = HyDEQueryTransform(include_original=True)\n",
    "hyde_query_engine_chunk_size = TransformQueryEngine(query_engine_chunk_size, hyde)\n",
    "response_HyDE_chunk_size = hyde_query_engine_chunk_size.query(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "You will be eligible for unemployment benefits in Germany if you meet certain criteria. According to the provided information, if you become unemployed in Germany and want to search for work in another EU member state, you can take your entitlement to German unemployment benefits for a period of three months (referred to as the \"Mitnahmezeitraum\"). This period can be extended for up to a maximum of six months for the purpose of job search. The specific percentage of your salary that you will receive as unemployment benefits is not mentioned in the given context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source 0:\n",
      "\tFile name: dok_ba013155.pdf\n",
      "\tPage: 22\n",
      "Source 1:\n",
      "\tFile name: dok_ba013155.pdf\n",
      "\tPage: 22\n",
      "Source 2:\n",
      "\tFile name: merkblatt-fuer-arbeitslose_ba036520.pdf\n",
      "\tPage: 26\n",
      "Source 3:\n",
      "\tFile name: dok_ba013155.pdf\n",
      "\tPage: 32\n",
      "Source 4:\n",
      "\tFile name: dok_ba013155.pdf\n",
      "\tPage: 24\n"
     ]
    }
   ],
   "source": [
    "print_response(response_HyDE_chunk_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(response):\n",
    "    N = len(response.source_nodes)\n",
    "    scores  = [response.source_nodes[i].score for i in range(N)]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8520634121940881,\n",
       " 0.8495681877333476,\n",
       " 0.8470285279883525,\n",
       " 0.8453798820266532,\n",
       " 0.8451710640669897]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_score(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8572357545733745,\n",
       " 0.8570144623198696,\n",
       " 0.8527991402582654,\n",
       " 0.851910417604173,\n",
       " 0.8468197305380054]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_score(response_chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8843449567325018,\n",
       " 0.8833562839707858,\n",
       " 0.8820011889899166,\n",
       " 0.8779475314934001,\n",
       " 0.8776750187342072]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_score(response_HyDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8892044539961814,\n",
       " 0.8842722173806833,\n",
       " 0.8828456505031381,\n",
       " 0.8752202744227146,\n",
       " 0.8749440691654466]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_score(response_HyDE_chunk_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_chatbot_afa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
